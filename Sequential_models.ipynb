{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e869ab8",
   "metadata": {},
   "source": [
    "# Sequential Deep Learning Models in Pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9de78412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "@author Alberto Bassi & Riccardo Tomada\n",
    "\"\"\"\n",
    "# Essential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "# Neural Networks\n",
    "from models import RNN_layer, LSTM_layer\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from time import sleep\n",
    "\n",
    "# Dates\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410e9852",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78aac233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close time</th>\n",
       "      <th>Quote asset volume</th>\n",
       "      <th>Number of trades</th>\n",
       "      <th>Taker buy base asset volume</th>\n",
       "      <th>Taker buy quote asset volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-06 03:00:00.000000000</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>1.7990</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>649.120</td>\n",
       "      <td>2017-11-06 03:59:59.999000064</td>\n",
       "      <td>7.251214e+02</td>\n",
       "      <td>33.0</td>\n",
       "      <td>207.450</td>\n",
       "      <td>3.514144e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-06 04:00:00.000000000</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>1.6500</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>1.6479</td>\n",
       "      <td>8147.720</td>\n",
       "      <td>2017-11-06 04:59:59.999000064</td>\n",
       "      <td>1.270853e+04</td>\n",
       "      <td>139.0</td>\n",
       "      <td>2130.590</td>\n",
       "      <td>3.436513e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-06 05:00:00.000000000</td>\n",
       "      <td>1.5457</td>\n",
       "      <td>1.5525</td>\n",
       "      <td>1.5455</td>\n",
       "      <td>1.5458</td>\n",
       "      <td>6628.200</td>\n",
       "      <td>2017-11-06 05:59:59.999000064</td>\n",
       "      <td>1.026534e+04</td>\n",
       "      <td>27.0</td>\n",
       "      <td>563.920</td>\n",
       "      <td>8.754265e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-06 06:00:00.000000000</td>\n",
       "      <td>1.5458</td>\n",
       "      <td>1.6810</td>\n",
       "      <td>1.5387</td>\n",
       "      <td>1.6810</td>\n",
       "      <td>22767.900</td>\n",
       "      <td>2017-11-06 06:59:59.999000064</td>\n",
       "      <td>3.650714e+04</td>\n",
       "      <td>133.0</td>\n",
       "      <td>12886.750</td>\n",
       "      <td>2.124768e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-06 07:00:00.000000000</td>\n",
       "      <td>1.6809</td>\n",
       "      <td>1.6809</td>\n",
       "      <td>1.6000</td>\n",
       "      <td>1.6250</td>\n",
       "      <td>14938.730</td>\n",
       "      <td>2017-11-06 07:59:59.999000064</td>\n",
       "      <td>2.427873e+04</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7162.660</td>\n",
       "      <td>1.164245e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34746</th>\n",
       "      <td>2021-10-28 20:00:00</td>\n",
       "      <td>491.0000</td>\n",
       "      <td>494.8000</td>\n",
       "      <td>477.9000</td>\n",
       "      <td>490.5000</td>\n",
       "      <td>90431.134</td>\n",
       "      <td>2021-10-28 20:59:59.999000064</td>\n",
       "      <td>4.444162e+07</td>\n",
       "      <td>75832.0</td>\n",
       "      <td>40715.355</td>\n",
       "      <td>2.003381e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34747</th>\n",
       "      <td>2021-10-28 21:00:00</td>\n",
       "      <td>490.5000</td>\n",
       "      <td>490.5000</td>\n",
       "      <td>485.8000</td>\n",
       "      <td>489.8000</td>\n",
       "      <td>37248.759</td>\n",
       "      <td>2021-10-28 21:59:59.999000064</td>\n",
       "      <td>1.818572e+07</td>\n",
       "      <td>43707.0</td>\n",
       "      <td>19556.122</td>\n",
       "      <td>9.550490e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34748</th>\n",
       "      <td>2021-10-28 22:00:00</td>\n",
       "      <td>489.9000</td>\n",
       "      <td>491.3000</td>\n",
       "      <td>488.5000</td>\n",
       "      <td>489.3000</td>\n",
       "      <td>38162.017</td>\n",
       "      <td>2021-10-28 22:59:59.999000064</td>\n",
       "      <td>1.871114e+07</td>\n",
       "      <td>28600.0</td>\n",
       "      <td>21584.731</td>\n",
       "      <td>1.058593e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34749</th>\n",
       "      <td>2021-10-28 23:00:00</td>\n",
       "      <td>489.3000</td>\n",
       "      <td>492.3000</td>\n",
       "      <td>487.4000</td>\n",
       "      <td>491.9000</td>\n",
       "      <td>49811.734</td>\n",
       "      <td>2021-10-28 23:59:59.999000064</td>\n",
       "      <td>2.442102e+07</td>\n",
       "      <td>28422.0</td>\n",
       "      <td>25969.233</td>\n",
       "      <td>1.273187e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34750</th>\n",
       "      <td>2021-10-29 00:00:00</td>\n",
       "      <td>492.0000</td>\n",
       "      <td>496.1000</td>\n",
       "      <td>488.3000</td>\n",
       "      <td>495.9000</td>\n",
       "      <td>49584.099</td>\n",
       "      <td>2021-10-29 00:59:59.999000064</td>\n",
       "      <td>2.441381e+07</td>\n",
       "      <td>36255.0</td>\n",
       "      <td>28833.995</td>\n",
       "      <td>1.420486e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34751 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Open Time      Open      High       Low     Close  \\\n",
       "0      2017-11-06 03:00:00.000000000    1.5000    1.7990    0.5000    1.7000   \n",
       "1      2017-11-06 04:00:00.000000000    1.3000    1.6500    1.3000    1.6479   \n",
       "2      2017-11-06 05:00:00.000000000    1.5457    1.5525    1.5455    1.5458   \n",
       "3      2017-11-06 06:00:00.000000000    1.5458    1.6810    1.5387    1.6810   \n",
       "4      2017-11-06 07:00:00.000000000    1.6809    1.6809    1.6000    1.6250   \n",
       "...                              ...       ...       ...       ...       ...   \n",
       "34746            2021-10-28 20:00:00  491.0000  494.8000  477.9000  490.5000   \n",
       "34747            2021-10-28 21:00:00  490.5000  490.5000  485.8000  489.8000   \n",
       "34748            2021-10-28 22:00:00  489.9000  491.3000  488.5000  489.3000   \n",
       "34749            2021-10-28 23:00:00  489.3000  492.3000  487.4000  491.9000   \n",
       "34750            2021-10-29 00:00:00  492.0000  496.1000  488.3000  495.9000   \n",
       "\n",
       "          Volume                     Close time  Quote asset volume  \\\n",
       "0        649.120  2017-11-06 03:59:59.999000064        7.251214e+02   \n",
       "1       8147.720  2017-11-06 04:59:59.999000064        1.270853e+04   \n",
       "2       6628.200  2017-11-06 05:59:59.999000064        1.026534e+04   \n",
       "3      22767.900  2017-11-06 06:59:59.999000064        3.650714e+04   \n",
       "4      14938.730  2017-11-06 07:59:59.999000064        2.427873e+04   \n",
       "...          ...                            ...                 ...   \n",
       "34746  90431.134  2021-10-28 20:59:59.999000064        4.444162e+07   \n",
       "34747  37248.759  2021-10-28 21:59:59.999000064        1.818572e+07   \n",
       "34748  38162.017  2021-10-28 22:59:59.999000064        1.871114e+07   \n",
       "34749  49811.734  2021-10-28 23:59:59.999000064        2.442102e+07   \n",
       "34750  49584.099  2021-10-29 00:59:59.999000064        2.441381e+07   \n",
       "\n",
       "       Number of trades  Taker buy base asset volume  \\\n",
       "0                  33.0                      207.450   \n",
       "1                 139.0                     2130.590   \n",
       "2                  27.0                      563.920   \n",
       "3                 133.0                    12886.750   \n",
       "4                  58.0                     7162.660   \n",
       "...                 ...                          ...   \n",
       "34746           75832.0                    40715.355   \n",
       "34747           43707.0                    19556.122   \n",
       "34748           28600.0                    21584.731   \n",
       "34749           28422.0                    25969.233   \n",
       "34750           36255.0                    28833.995   \n",
       "\n",
       "       Taker buy quote asset volume  \n",
       "0                      3.514144e+02  \n",
       "1                      3.436513e+03  \n",
       "2                      8.754265e+02  \n",
       "3                      2.124768e+04  \n",
       "4                      1.164245e+04  \n",
       "...                             ...  \n",
       "34746                  2.003381e+07  \n",
       "34747                  9.550490e+06  \n",
       "34748                  1.058593e+07  \n",
       "34749                  1.273187e+07  \n",
       "34750                  1.420486e+07  \n",
       "\n",
       "[34751 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize as pandas dataframe\n",
    "df = pd.read_csv(\"bitcoin_dataset.csv\",usecols = (1,2,3,4,5,6,7,8,9,10,11))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76bd74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a costum dataset class\n",
    "class BinanceDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        csv_file (string): Path to the csv file.\n",
    "        seq_length (int): length of the temporal sequence\n",
    "        transform (callable, optional): Optional transform to be applied\n",
    "            on a sample.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Read the file and split the lines in a list\n",
    "        with open(csv_file, 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            \n",
    "        # Get x and y values from each line and append to self.data\n",
    "        self.data = []\n",
    "        \n",
    "        # Take maximum number of days\n",
    "        num_lines = len(lines)\n",
    "        num_days = num_lines//24\n",
    "        \n",
    "        for day in range(num_days):\n",
    "            day_sample = []\n",
    "            for line in lines[1 + day*24: (day+1)*24 +1]:\n",
    "                sample = line.split(',')\n",
    "                # Take opening and clsure times \n",
    "                # Uncomment if they were different for each time\n",
    "                #opening = pd.to_datetime(sample[1], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "                #closure = pd.to_datetime(sample[7], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "                # Add as first element the total time of operation\n",
    "                #samples = [(closure-opening).total_seconds()]\n",
    "                samples = []\n",
    "\n",
    "                len_sample = len(sample)\n",
    "\n",
    "                for i in range(1,len_sample):\n",
    "                    # Exclude opening and closure time\n",
    "                    if i!=1 and i!=7:\n",
    "                        # Convert to float and append to samples\n",
    "                        sample[i] = float(sample[i])\n",
    "                        samples.append(sample[i])\n",
    "\n",
    "                day_sample.append(samples)\n",
    "            \n",
    "            self.data.append(day_sample)\n",
    "    def __len__(self):\n",
    "        # The length of the dataset is simply the length of the self.data list\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Our sample is the element idx of the list self.data\n",
    "        sample = self.data[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "50348687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        return (torch.tensor(sample).float())\n",
    "    \n",
    "# Dataset\n",
    "composed_transform = transforms.Compose([ToTensor()] )\n",
    "dataset = BinanceDataset('bitcoin_dataset.csv', transform=composed_transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eec58191",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split to define validation and train dataset\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [1300, 148])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f600a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "train_dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "val_dataloader  = DataLoader(val_dataset,  batch_size= 64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6ec3261b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 24, 10])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f58bb2",
   "metadata": {},
   "source": [
    "## Define the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3e247605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTM_layer(\n",
       "  (forget_gate): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (input_gate): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (cell_update): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (out): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "### Set the random seed for reproducible results\n",
    "torch.manual_seed(0)\n",
    "\n",
    "### Initialize the two networks\n",
    "x_dim = 10\n",
    "h_dim = 10\n",
    "\n",
    "len_seq = 24\n",
    "\n",
    "net = LSTM_layer(x_dim, h_dim)\n",
    "\n",
    "### Move to device\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0bfaf0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6453, 0.3389, 0.5321, 0.5557, 0.3905, 0.5548, 0.6733, 0.2914,\n",
      "          0.3411, 0.3984],\n",
      "         [0.7234, 0.6774, 0.4375, 0.5262, 0.7028, 0.4999, 0.2970, 0.5920,\n",
      "          0.5780, 0.6527],\n",
      "         [0.5668, 0.4067, 0.5769, 0.5775, 0.6048, 0.5065, 0.5415, 0.5179,\n",
      "          0.4812, 0.4045],\n",
      "         [0.6593, 0.5167, 0.4205, 0.6979, 0.3313, 0.5890, 0.4050, 0.5845,\n",
      "          0.4504, 0.2800],\n",
      "         [0.5360, 0.3401, 0.2517, 0.3842, 0.4336, 0.3488, 0.6318, 0.5053,\n",
      "          0.3117, 0.5919],\n",
      "         [0.6598, 0.4011, 0.4593, 0.2735, 0.4766, 0.7157, 0.4586, 0.2587,\n",
      "          0.4549, 0.4360],\n",
      "         [0.4878, 0.5485, 0.4623, 0.7217, 0.6492, 0.2805, 0.4145, 0.7951,\n",
      "          0.4567, 0.5744],\n",
      "         [0.4377, 0.4854, 0.5220, 0.6182, 0.4346, 0.5445, 0.6388, 0.5347,\n",
      "          0.4321, 0.4781],\n",
      "         [0.5725, 0.2598, 0.6299, 0.5263, 0.4217, 0.5860, 0.6674, 0.3445,\n",
      "          0.5671, 0.4494],\n",
      "         [0.4787, 0.5789, 0.4981, 0.5357, 0.5316, 0.2818, 0.4687, 0.6387,\n",
      "          0.4416, 0.6325],\n",
      "         [0.5980, 0.4288, 0.5062, 0.3940, 0.4814, 0.6488, 0.3858, 0.3742,\n",
      "          0.3793, 0.4068],\n",
      "         [0.4387, 0.3942, 0.7238, 0.5049, 0.5733, 0.6488, 0.3919, 0.5384,\n",
      "          0.6183, 0.4732],\n",
      "         [0.4941, 0.4523, 0.6548, 0.6141, 0.4250, 0.3305, 0.6252, 0.5317,\n",
      "          0.2691, 0.5456],\n",
      "         [0.5433, 0.2624, 0.6017, 0.5447, 0.4490, 0.3484, 0.7191, 0.5432,\n",
      "          0.3970, 0.5156],\n",
      "         [0.3604, 0.3677, 0.6039, 0.3946, 0.6127, 0.3072, 0.7174, 0.3928,\n",
      "          0.4985, 0.7076],\n",
      "         [0.8155, 0.5869, 0.3478, 0.5561, 0.1505, 0.5580, 0.6503, 0.1507,\n",
      "          0.5545, 0.3856],\n",
      "         [0.6163, 0.5954, 0.5312, 0.6068, 0.4692, 0.4541, 0.4277, 0.5073,\n",
      "          0.4614, 0.4779],\n",
      "         [0.6837, 0.4392, 0.4073, 0.5201, 0.3173, 0.2746, 0.7090, 0.2319,\n",
      "          0.2301, 0.4996],\n",
      "         [0.3962, 0.4088, 0.5405, 0.2164, 0.5071, 0.8137, 0.2695, 0.3647,\n",
      "          0.6417, 0.4592],\n",
      "         [0.6757, 0.5937, 0.3680, 0.4794, 0.5354, 0.4845, 0.3005, 0.4216,\n",
      "          0.5515, 0.5350],\n",
      "         [0.4000, 0.3842, 0.5715, 0.2877, 0.4113, 0.7060, 0.3512, 0.4648,\n",
      "          0.4851, 0.5695],\n",
      "         [0.6276, 0.5127, 0.5307, 0.2497, 0.5522, 0.5463, 0.3468, 0.2317,\n",
      "          0.5293, 0.6141],\n",
      "         [0.3584, 0.4616, 0.6215, 0.2716, 0.6824, 0.5792, 0.3907, 0.1912,\n",
      "          0.5856, 0.6626],\n",
      "         [0.6517, 0.6552, 0.3283, 0.6442, 0.2922, 0.3102, 0.7215, 0.3093,\n",
      "          0.4633, 0.4601]]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Check if the nets are working properly\n",
    "\n",
    "x = torch.randn(1,len_seq,x_dim)\n",
    "h = torch.randn(1,len_seq,h_dim)\n",
    "C = torch.randn(1,len_seq,h_dim)\n",
    "\n",
    "out = net(x,h, C)\n",
    "print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ef963a",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8f65dfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8fdc146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = torch.optim.RMSprop(net.parameters())\n",
    "\n",
    "# Define the loss function\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75a74f4",
   "metadata": {},
   "source": [
    "## Training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "76237707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net, device, dataloader, loss_function, optimizer):\n",
    "    \"\"\"\n",
    "    Train an epoch of data\n",
    "    -----------\n",
    "    Parameters:\n",
    "    net = network\n",
    "    device = training device (cuda/cpu)\n",
    "    dataloader = dataloader of data\n",
    "    loss_function = loss function\n",
    "    optimzer = optimizer used\n",
    "    --------\n",
    "    Returns:\n",
    "    mean(train_epoch_loss) = average epoch loss\n",
    "    \"\"\"\n",
    "    # Set the train mode\n",
    "    net.train()\n",
    "    # List to save batch losses\n",
    "    train_epoch_loss = []\n",
    "    # Iterate the dataloader\n",
    "    for batch in dataloader:\n",
    "\n",
    "        # Move to device\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        # Prepare input\n",
    "        x_input = batch[:, :-1,:]\n",
    "        labels = batch[:,1:, :]\n",
    "        \n",
    "        a_0 = torch.zeros(64,23,10)\n",
    "        c_0 = torch.zeros(64,23,10)\n",
    "        # Forward pass (we do not need recurrent state now)\n",
    "        net_out, _, _ = net(x_input, a_0, c_0) \n",
    "        \n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_function(net_out, labels)\n",
    "        \n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute batch losses\n",
    "        train_batch_loss = loss.detach().cpu().numpy()\n",
    "        train_epoch_loss.append(train_batch_loss)\n",
    "        \n",
    "    return np.mean(train_epoch_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "85205078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65bb885671d42ca9d3517b8c2aaff0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 23, 10])\n",
      "torch.Size([64, 23, 10])\n",
      "torch.Size([64, 23, 10])\n",
      "torch.Size([64, 23, 10])\n",
      "torch.Size([64, 23, 10])\n",
      "torch.Size([64, 23, 10])\n",
      "torch.Size([64, 23, 10])\n",
      "torch.Size([64, 23, 10])\n",
      "torch.Size([64, 23, 10])\n",
      "torch.Size([64, 23, 10])\n",
      "torch.Size([64, 23, 10])\n",
      "torch.Size([64, 23, 10])\n",
      "torch.Size([64, 23, 10])\n",
      "torch.Size([64, 23, 10])\n",
      "torch.Size([64, 23, 10])\n",
      "torch.Size([64, 23, 10])\n",
      "torch.Size([64, 23, 10])\n",
      "torch.Size([64, 23, 10])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 10 at dim 1 (got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-8adcdff6b19a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-983d39e6d550>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(net, device, dataloader, loss_function, optimizer)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtrain_epoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Iterate the dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Move to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-e9ca93856343>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-8a7a95187a90>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 10 at dim 1 (got 0)"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "\n",
    "pbar = tqdm_notebook(range(num_epochs))\n",
    "\n",
    "train_losses = []\n",
    "for epoch in pbar:\n",
    "    epoch_loss = train_epoch(net, device, train_dataloader, loss_function, optimizer)\n",
    "    train_losses.append(train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c0c280",
   "metadata": {},
   "source": [
    "## Save and load model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
